from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.cron import CronTrigger
from apscheduler.triggers.interval import IntervalTrigger
from datetime import datetime, date, timedelta
from sqlalchemy.orm import Session
from database import SessionLocal, settings
from models import User, Subscription, NewsCache, SystemLog, TopicRefreshStatus, CustomRSSFeed
from news_fetcher import NewsFetcher, deduplicate_articles
from summarizer import get_summarizer
import logging
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
import uuid
import pytz

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Initialize scheduler
scheduler = BackgroundScheduler(timezone=settings.TIMEZONE)


def get_current_date_in_timezone() -> str:
    """è·å–é…ç½®æ—¶åŒºçš„å½“å‰æ—¥æœŸï¼ˆYYYY-MM-DDæ ¼å¼ï¼‰"""
    tz = pytz.timezone(settings.TIMEZONE)
    return datetime.now(tz).date().strftime("%Y-%m-%d")


def update_news_for_topic(topic: str, date_str: str, db: Session, lock_id: str = None) -> dict:
    """Update news for a specific topic (optimized: one topic refresh instead of per-user)
    
    Args:
        topic: Topic name
        date_str: Date string (YYYY-MM-DD)
        db: Database session
        lock_id: Lock ID for concurrent refresh protection
    
    Returns:
        dict: {"success": bool, "articles_count": int, "error": str}
    """
    try:
        # Get all active custom RSS feeds for this topic (from all users)
        custom_feeds = db.query(CustomRSSFeed).filter(
            CustomRSSFeed.topic == topic,
            CustomRSSFeed.is_active == True
        ).all()
        
        # Convert to list of dicts for NewsFetcher
        custom_rss_feeds = [
            {
                "topic": feed.topic,
                "feed_url": feed.feed_url,
                "is_active": feed.is_active
            }
            for feed in custom_feeds
        ]
        
        fetcher = NewsFetcher(custom_rss_feeds=custom_rss_feeds)
        summarizer = get_summarizer()
        
        logger.info(f"Fetching news for topic: {topic} (date: {date_str})")
        
        # Fetch news articles - limit to 16 per topic
        articles = fetcher.fetch_news(topic, max_articles=16)
        
        if not articles:
            logger.warning(f"No articles found for topic: {topic}")
            return {"success": True, "articles_count": 0, "error": None}
        
        # Deduplicate
        articles = deduplicate_articles(articles)
        
        # Limit to 16 articles
        articles = articles[:16]
        
        updated_count = 0
        created_count = 0
        
        # Process articles one by one and save immediately
        for article in articles:
            try:
                # For RSS articles, check by entry_id first (before LLM processing)
                entry_id = article.get("entry_id")
                existing = None
                
                if entry_id:
                    # Check if article already exists by entry_id (for RSS feeds)
                    existing = db.query(NewsCache).filter(
                        NewsCache.entry_id == entry_id
                    ).first()
                else:
                    # For non-RSS articles (GNews, NewsData), check by URL + date + topic
                    existing = db.query(NewsCache).filter(
                        NewsCache.url == article["url"],
                        NewsCache.date == date_str,
                        NewsCache.topic == topic
                    ).first()
                
                # If already exists, skip LLM processing
                if existing:
                    logger.debug(f"Article already exists, skipping LLM processing: {article.get('title', 'Unknown')[:50]}...")
                    continue
                
                # Only process with LLM if article doesn't exist
                # Normal summary
                summary_normal = summarizer.generate_summary(
                    article["title"],
                    article["content"],
                    roast_mode=False
                )
                
                # Roast mode summary
                summary_roast = summarizer.generate_summary(
                    article["title"],
                    article["content"],
                    roast_mode=True
                )
                
                # Evaluate relevance score
                relevance_score = summarizer.evaluate_relevance(
                    topic,
                    article["title"],
                    article.get("content", "")
                )
                
                # Create new cache entry
                news_cache = NewsCache(
                    topic=topic,
                    title=article["title"],
                    summary=summary_normal,
                    summary_roast=summary_roast,
                    url=article["url"],
                    source=article.get("source"),
                    image_url=article.get("image_url"),
                    published_at=article.get("published_at"),
                    date=date_str,
                    relevance_score=relevance_score,
                    raw_content=article.get("content", "")[:1000],  # Truncate
                    entry_id=entry_id  # Store entry_id for RSS articles
                )
                db.add(news_cache)
                created_count += 1
                
                # Commit after each article to save immediately
                db.commit()
                logger.debug(f"Saved article '{article.get('title', 'Unknown')[:50]}...' for topic {topic}")
                    
            except Exception as e:
                logger.error(f"Error processing article '{article.get('title', 'Unknown')}' for topic {topic}: {str(e)}")
                db.rollback()  # Rollback on error
                continue
        
        total_count = updated_count + created_count
        logger.info(f"Updated {total_count} articles for topic: {topic} (created: {created_count}, updated: {updated_count})")
        
        return {"success": True, "articles_count": total_count, "error": None}
        
    except Exception as e:
        logger.error(f"Error updating news for topic {topic}: {str(e)}")
        db.rollback()
        return {"success": False, "articles_count": 0, "error": str(e)}


def get_or_create_refresh_status(topic: str, date_str: str, db: Session) -> TopicRefreshStatus:
    """Get or create refresh status for a topic+date"""
    status = db.query(TopicRefreshStatus).filter(
        TopicRefreshStatus.topic == topic,
        TopicRefreshStatus.date == date_str
    ).first()
    
    if not status:
        status = TopicRefreshStatus(
            topic=topic,
            date=date_str,
            is_refreshing=False,
            last_refreshed_at=None
        )
        db.add(status)
        db.commit()
        db.refresh(status)
    
    return status


def can_refresh_topic(topic: str, date_str: str, db: Session, min_interval_minutes: int = 5) -> tuple[bool, str, TopicRefreshStatus]:
    """Check if a topic can be refreshed (not recently refreshed and not currently refreshing)
    
    Returns:
        (can_refresh: bool, reason: str, status: TopicRefreshStatus)
    """
    status = get_or_create_refresh_status(topic, date_str, db)
    
    # Check if currently refreshing
    if status.is_refreshing:
        # Check if lock is stale (older than 10 minutes)
        if status.refresh_lock_id:
            # Lock exists, consider it stale if last_refreshed_at is old
            if status.last_refreshed_at:
                lock_age = datetime.utcnow() - status.last_refreshed_at
                if lock_age.total_seconds() > 600:  # 10 minutes
                    logger.warning(f"Stale lock detected for {topic} on {date_str}, clearing it")
                    status.is_refreshing = False
                    status.refresh_lock_id = None
                    db.commit()
                    db.refresh(status)
                else:
                    return (False, "currently_refreshing", status)
            else:
                # Lock exists but no refresh time, clear it
                status.is_refreshing = False
                status.refresh_lock_id = None
                db.commit()
                db.refresh(status)
    
    # Check if recently refreshed
    if status.last_refreshed_at:
        time_since_refresh = datetime.utcnow() - status.last_refreshed_at
        if time_since_refresh.total_seconds() < min_interval_minutes * 60:
            remaining_seconds = int(min_interval_minutes * 60 - time_since_refresh.total_seconds())
            return (False, f"recently_refreshed_{remaining_seconds}s", status)
    
    return (True, "ok", status)


def mark_refreshing(topic: str, date_str: str, lock_id: str, db: Session):
    """Mark topic as refreshing"""
    status = get_or_create_refresh_status(topic, date_str, db)
    status.is_refreshing = True
    status.refresh_lock_id = lock_id
    db.commit()


def mark_refreshed(topic: str, date_str: str, db: Session):
    """Mark topic as refreshed"""
    status = get_or_create_refresh_status(topic, date_str, db)
    status.is_refreshing = False
    status.refresh_lock_id = None
    status.last_refreshed_at = datetime.utcnow()
    db.commit()


def refresh_topic_with_lock(topic: str, date_str: str, db: Session) -> dict:
    """Refresh a topic with lock protection
    
    Returns:
        dict: {"success": bool, "articles_count": int, "skipped": bool, "reason": str}
    """
    lock_id = str(uuid.uuid4())
    
    # Check if can refresh
    can_refresh, reason, status = can_refresh_topic(topic, date_str, db)
    
    if not can_refresh:
        if reason.startswith("recently_refreshed"):
            return {
                "success": True,
                "articles_count": 0,
                "skipped": True,
                "reason": reason
            }
        elif reason == "currently_refreshing":
            return {
                "success": False,
                "articles_count": 0,
                "skipped": True,
                "reason": "currently_refreshing"
            }
    
    # Mark as refreshing
    try:
        mark_refreshing(topic, date_str, lock_id, db)
        
        # Refresh news
        result = update_news_for_topic(topic, date_str, db, lock_id)
        
        # Mark as refreshed
        mark_refreshed(topic, date_str, db)
        
        result["skipped"] = False
        result["reason"] = "refreshed"
        return result
        
    except Exception as e:
        logger.error(f"Error refreshing topic {topic}: {str(e)}")
        # Clear lock on error
        try:
            status = get_or_create_refresh_status(topic, date_str, db)
            status.is_refreshing = False
            status.refresh_lock_id = None
            db.commit()
        except:
            pass
        return {
            "success": False,
            "articles_count": 0,
            "skipped": False,
            "reason": "error",
            "error": str(e)
        }


# ä¿ç•™å‘åå…¼å®¹çš„å‡½æ•°ï¼ˆç”¨äºé‚®ä»¶å‘é€ç­‰åœºæ™¯ï¼‰
def update_news_for_user(user_id: int, db: Session):
    """Update news for a specific user's subscriptions (legacy function, now uses topic-level refresh)
    
    This function is kept for backward compatibility but now uses the optimized topic-level refresh.
    """
    try:
        user = db.query(User).filter(User.id == user_id).first()
        if not user:
            logger.error(f"User {user_id} not found")
            return
        
        subscriptions = db.query(Subscription).filter(
            Subscription.user_id == user_id,
            Subscription.is_active == True
        ).all()
        
        # Get user's active custom RSS feeds
        custom_feeds = db.query(CustomRSSFeed).filter(
            CustomRSSFeed.user_id == user_id,
            CustomRSSFeed.is_active == True
        ).all()
        
        # Collect unique topics from both subscriptions and custom RSS feeds
        topics = set([sub.topic for sub in subscriptions])
        topics.update([feed.topic for feed in custom_feeds])
        topics = list(topics)
        
        if not topics:
            logger.info(f"No active subscriptions or custom RSS feeds for user {user.email}")
            return
        
        today = get_current_date_in_timezone()
        
        # Refresh each topic (will use lock protection)
        for topic in topics:
            refresh_topic_with_lock(topic, today, db)
        
    except Exception as e:
        logger.error(f"Error updating news for user {user_id}: {str(e)}")


def daily_news_update():
    """Daily scheduled task to update news for all users (optimized: topic-level refresh)"""
    logger.info("Starting daily news update (optimized)...")
    
    db = SessionLocal()
    try:
        # Get all active users with subscriptions
        users = db.query(User).filter(User.is_active == True).all()
        
        if not users:
            logger.info("No active users found")
            return
        
        # Collect all unique topics from all users' subscriptions
        all_topics = set()
        user_count = 0
        
        for user in users:
            subscriptions = db.query(Subscription).filter(
                Subscription.user_id == user.id,
                Subscription.is_active == True
            ).all()
            
            # Get user's active custom RSS feeds
            custom_feeds = db.query(CustomRSSFeed).filter(
                CustomRSSFeed.user_id == user.id,
                CustomRSSFeed.is_active == True
            ).all()
            
            # Collect topics from both subscriptions and custom RSS feeds
            user_topics = set([sub.topic for sub in subscriptions])
            user_topics.update([feed.topic for feed in custom_feeds])
            
            if user_topics:
                user_count += 1
                all_topics.update(user_topics)
        
        logger.info(f"Found {len(all_topics)} unique topics from {user_count} users with subscriptions")
        
        today = get_current_date_in_timezone()
        
        # Refresh each topic (will handle locks and duplicates)
        refreshed_topics = 0
        skipped_topics = 0
        
        for topic in all_topics:
            result = refresh_topic_with_lock(topic, today, db)
            if result["skipped"]:
                skipped_topics += 1
            else:
                refreshed_topics += 1
        
        # Log completion
        log = SystemLog(
            log_type="fetch",
            message="Daily news update completed (optimized)",
            log_metadata={
                "users_count": user_count,
                "topics_count": len(all_topics),
                "refreshed_topics": refreshed_topics,
                "skipped_topics": skipped_topics,
                "timestamp": datetime.utcnow().isoformat()
            }
        )
        db.add(log)
        db.commit()
        
        logger.info(f"Daily news update completed: {refreshed_topics} topics refreshed, {skipped_topics} skipped")
        
    except Exception as e:
        logger.error(f"Daily news update failed: {str(e)}")
        db.rollback()
        import traceback
        traceback.print_exc()
    finally:
        db.close()


def send_scheduled_emails():
    """å®šæ—¶é‚®ä»¶ä»»åŠ¡ - æ£€æŸ¥æ‰€æœ‰ç”¨æˆ·å¹¶å‘é€é‚®ä»¶ï¼ˆæ ¹æ®æ¯ä¸ªç”¨æˆ·çš„é…ç½®ï¼‰
    
    æ³¨æ„ï¼šæ­¤å‡½æ•°åªä»æ•°æ®åº“è¯»å–å·²ç¼“å­˜çš„æ–°é—»ï¼Œä¸ä¼šè§¦å‘æ–°é—»åˆ·æ–°ã€‚
    æ–°é—»åˆ·æ–°ç”± daily_news_update ä»»åŠ¡ç‹¬ç«‹å¤„ç†ã€‚
    """
    logger.info("Starting scheduled email check task...")
    
    db = SessionLocal()
    try:
        # ç›´æ¥ä»æ•°æ®åº“è¯»å–æ–°é—»ï¼Œä¸è§¦å‘åˆ·æ–°
        # æ£€æŸ¥å¹¶å‘é€é‚®ä»¶ï¼ˆæ ¹æ®æ¯ä¸ªç”¨æˆ·çš„å®šæ—¶é…ç½®ï¼‰
        send_daily_emails(db)
        
        logger.info("Scheduled email task completed successfully")
        
    except Exception as e:
        logger.error(f"Scheduled email task failed: {str(e)}")
        db.rollback()
        import traceback
        traceback.print_exc()
    finally:
        db.close()


def should_send_email_to_user(user: User, current_time: datetime) -> bool:
    """æ£€æŸ¥æ˜¯å¦åº”è¯¥å‘ç”¨æˆ·å‘é€é‚®ä»¶ï¼ˆæ ¹æ®ç”¨æˆ·çš„å®šæ—¶é…ç½®ï¼Œä»…æ”¯æŒæ¯å¤©å›ºå®šæ—¶é—´ï¼‰
    
    ä½¿ç”¨é…ç½®çš„æ—¶åŒºæ¥æ¯”è¾ƒæ—¶é—´ï¼Œç¡®ä¿æ—¶åŒºä¸€è‡´æ€§ã€‚
    """
    if not user.email_notifications or not user.email_schedule_enabled:
        return False
    
    # åªæ”¯æŒ daily æ¨¡å¼
    schedule_type = user.email_schedule_type
    if schedule_type != "daily":
        return False
    
    last_sent = user.last_email_sent_at
    
    # æ¯å¤©å›ºå®šæ—¶é—´å‘é€
    target_hour = user.email_schedule_hour
    target_minute = user.email_schedule_minute
    
    # æ£€æŸ¥å½“å‰æ—¶é—´æ˜¯å¦åŒ¹é…ç›®æ ‡æ—¶é—´ï¼ˆå…è®¸åœ¨ç›®æ ‡æ—¶é—´åçš„1å°æ—¶å†…å‘é€ï¼‰
    # ä½¿ç”¨é…ç½®çš„æ—¶åŒºæ¥æ¯”è¾ƒ
    if current_time.hour == target_hour and current_time.minute >= target_minute:
        # å¦‚æœä»Šå¤©è¿˜æ²¡å‘é€è¿‡ï¼ˆä½¿ç”¨é…ç½®æ—¶åŒºçš„æ—¥æœŸï¼‰
        current_date = current_time.date()
        if not last_sent:
            return True
        # å°† last_sent è½¬æ¢ä¸ºé…ç½®æ—¶åŒºè¿›è¡Œæ¯”è¾ƒ
        tz = pytz.timezone(settings.TIMEZONE)
        if last_sent.tzinfo is None:
            # å¦‚æœ last_sent æ˜¯ naive datetimeï¼Œå‡è®¾å®ƒæ˜¯ UTC
            last_sent_tz = pytz.UTC.localize(last_sent)
        else:
            last_sent_tz = last_sent
        # è½¬æ¢ä¸ºé…ç½®æ—¶åŒº
        last_sent_in_tz = last_sent_tz.astimezone(tz)
        if last_sent_in_tz.date() < current_date:
            return True
    
    return False


def send_email_to_user(user_id: int, db: Session):
    """å‘æŒ‡å®šç”¨æˆ·å‘é€é‚®ä»¶"""
    try:
        user = db.query(User).filter(User.id == user_id).first()
        if not user:
            logger.error(f"User {user_id} not found")
            return
        
        if not user.email_notifications:
            logger.info(f"User {user.email} has email notifications disabled")
            return
        
        # Get user's subscriptions
        subscriptions = db.query(Subscription).filter(
            Subscription.user_id == user.id,
            Subscription.is_active == True
        ).all()
        
        if not subscriptions:
            logger.info(f"User {user.email} has no active subscriptions")
            return
        
        today = get_current_date_in_timezone()
        
        # Build email content
        email_body = build_email_digest(user, subscriptions, today, db)
        
        # Send email
        send_email(user.email, f"ğŸ“° Daily Digest - {today}", email_body)
        
        # Update last sent time (ä½¿ç”¨é…ç½®æ—¶åŒºçš„å½“å‰æ—¶é—´)
        tz = pytz.timezone(settings.TIMEZONE)
        user.last_email_sent_at = datetime.now(tz)
        db.commit()
        
        logger.info(f"Sent email to {user.email}")
        
    except Exception as e:
        logger.error(f"Failed to send email to user {user_id}: {str(e)}")
        db.rollback()


def send_daily_emails(db: Session):
    """æ£€æŸ¥æ‰€æœ‰ç”¨æˆ·å¹¶å‘é€é‚®ä»¶ï¼ˆæ ¹æ®æ¯ä¸ªç”¨æˆ·çš„å®šæ—¶é…ç½®ï¼‰
    
    ä½¿ç”¨é…ç½®çš„æ—¶åŒºï¼ˆsettings.TIMEZONEï¼‰æ¥è·å–å½“å‰æ—¶é—´ï¼Œè€Œä¸æ˜¯æœåŠ¡å™¨æœ¬åœ°æ—¶é—´ã€‚
    """
    try:
        # Get all active users with email notifications enabled
        users = db.query(User).filter(
            User.is_active == True,
            User.email_notifications == True
        ).all()
        
        if not users:
            logger.info("No users with email notifications enabled")
            return
        
        # ä½¿ç”¨é…ç½®çš„æ—¶åŒºè·å–å½“å‰æ—¶é—´ï¼Œè€Œä¸æ˜¯æœåŠ¡å™¨æœ¬åœ°æ—¶é—´
        tz = pytz.timezone(settings.TIMEZONE)
        current_time = datetime.now(tz)
        sent_count = 0
        
        for user in users:
            try:
                # Check if should send email based on user's schedule
                if should_send_email_to_user(user, current_time):
                    send_email_to_user(user.id, db)
                    sent_count += 1
                else:
                    logger.debug(f"Skipping email for {user.email} (schedule not met)")
                    
            except Exception as e:
                logger.error(f"Failed to process email for user {user.email}: {str(e)}")
        
        # Log completion
        today = get_current_date_in_timezone()
        log = SystemLog(
            log_type="email",
            message=f"Processed scheduled emails, sent to {sent_count} users",
            log_metadata={"date": today, "total_users": len(users), "sent_count": sent_count}
        )
        db.add(log)
        db.commit()
        
        logger.info(f"Email check completed: {sent_count}/{len(users)} users received emails")
        
    except Exception as e:
        logger.error(f"Email sending failed: {str(e)}")
        db.rollback()


def build_email_digest(user: User, subscriptions: list, date_str: str, db: Session) -> str:
    """Build HTML email digest"""
    html = f"""
    <html>
    <head>
        <style>
            body {{ font-family: Arial, sans-serif; line-height: 1.6; color: #333; }}
            h1 {{ color: #2563eb; }}
            h2 {{ color: #1e40af; border-bottom: 2px solid #3b82f6; padding-bottom: 5px; }}
            .news-item {{ margin: 15px 0; padding: 10px; background: #f3f4f6; border-radius: 5px; }}
            .news-title {{ font-weight: bold; color: #1f2937; }}
            .news-summary {{ margin: 5px 0; }}
            a {{ color: #2563eb; text-decoration: none; }}
            a:hover {{ text-decoration: underline; }}
        </style>
    </head>
    <body>
        <h1>ğŸ“° Daily Digest - {date_str}</h1>
        <p>Hi {user.email},</p>
        <p>Here's your personalized news digest for today:</p>
    """
    
    for sub in subscriptions:
        # Get news for this topic
        news_items = db.query(NewsCache).filter(
            NewsCache.topic == sub.topic,
            NewsCache.date == date_str
        ).limit(5).all()
        
        if not news_items:
            continue
        
        html += f"\n<h2>{sub.topic}</h2>\n"
        
        for item in news_items:
            summary = item.summary_roast if sub.roast_mode else item.summary
            html += f"""
            <div class="news-item">
                <div class="news-title">{item.title}</div>
                <div class="news-summary">{summary}</div>
                <a href="{item.url}" target="_blank">Read more â†’</a>
            </div>
            """
    
    html += """
        <hr>
        <p style="color: #6b7280; font-size: 12px;">
            You're receiving this because you enabled email notifications in Daily Digest Agent.
            <br>To unsubscribe, please update your settings in the dashboard.
        </p>
    </body>
    </html>
    """
    
    return html


def send_email(to_email: str, subject: str, html_body: str):
    """Send email via SMTP or Resend, using default account if configured
    
    Raises:
        ValueError: If no email service is configured
        Exception: If email sending fails
    """
    last_error = None
    
    # Try Resend first (if configured)
    if settings.RESEND_API_KEY and settings.RESEND_API_KEY != "":
        try:
            import resend
            resend.api_key = settings.RESEND_API_KEY
            
            params = {
                "from": settings.FROM_EMAIL,
                "to": [to_email],
                "subject": subject,
                "html": html_body,
            }
            
            resend.Emails.send(params)
            logger.info(f"Email sent via Resend to {to_email}")
            return
        except Exception as e:
            last_error = e
            logger.error(f"Resend email failed: {str(e)}")
            # Continue to try SMTP
    
    # Use default email account if configured, otherwise use SMTP settings
    smtp_user = settings.DEFAULT_EMAIL_ACCOUNT if settings.DEFAULT_EMAIL_ACCOUNT else settings.SMTP_USER
    smtp_password = settings.DEFAULT_EMAIL_PASSWORD if settings.DEFAULT_EMAIL_PASSWORD else settings.SMTP_PASSWORD
    
    # Fallback to SMTP
    if settings.SMTP_HOST and smtp_user and smtp_password:
        try:
            msg = MIMEMultipart('alternative')
            msg['Subject'] = subject
            msg['From'] = smtp_user
            msg['To'] = to_email
            
            html_part = MIMEText(html_body, 'html', 'utf-8')
            msg.attach(html_part)
            
            # Try SSL first (port 465), then TLS (port 587)
            if settings.SMTP_PORT == 465:
                # Use SSL connection
                server = smtplib.SMTP_SSL(settings.SMTP_HOST, settings.SMTP_PORT, timeout=30)
                server.login(smtp_user, smtp_password)
                server.send_message(msg)
                server.quit()
            else:
                # Use TLS connection
                with smtplib.SMTP(settings.SMTP_HOST, settings.SMTP_PORT, timeout=30) as server:
                    server.starttls()
                    server.login(smtp_user, smtp_password)
                    server.send_message(msg)
            
            logger.info(f"Email sent via SMTP to {to_email} (from {smtp_user})")
            return
            
        except smtplib.SMTPAuthenticationError as e:
            error_msg = f"SMTPè®¤è¯å¤±è´¥: {str(e)}\næç¤ºï¼šGmailç”¨æˆ·éœ€è¦ä½¿ç”¨'åº”ç”¨ä¸“ç”¨å¯†ç 'è€Œä¸æ˜¯æ™®é€šå¯†ç "
            logger.error(error_msg)
            raise ValueError(error_msg) from e
        except (smtplib.SMTPConnectError, ConnectionError, TimeoutError) as e:
            error_msg = f"SMTPè¿æ¥å¤±è´¥: {str(e)}\næç¤ºï¼šè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥ã€é˜²ç«å¢™è®¾ç½®å’ŒSMTPæœåŠ¡å™¨åœ°å€"
            logger.error(error_msg)
            raise ValueError(error_msg) from e
        except Exception as e:
            last_error = e
            error_msg = f"SMTPé‚®ä»¶å‘é€å¤±è´¥: {str(e)}"
            logger.error(error_msg)
            raise Exception(error_msg) from e
    
    # No email service configured
    error_msg = "æœªé…ç½®é‚®ä»¶æœåŠ¡ã€‚è¯·é…ç½®ä»¥ä¸‹ä¹‹ä¸€ï¼š\n1. RESEND_API_KEY\n2. SMTP_HOST + DEFAULT_EMAIL_ACCOUNT + DEFAULT_EMAIL_PASSWORD"
    logger.error(error_msg)
    if last_error:
        raise Exception(f"{error_msg}\næœ€åå°è¯•çš„é”™è¯¯: {str(last_error)}") from last_error
    else:
        raise ValueError(error_msg)


def start_scheduler():
    """Start the background scheduler - checks user schedules every hour"""
    try:
        # Daily news update at configured time (optimized)
        scheduler.add_job(
            daily_news_update,
            CronTrigger(
                hour=settings.DAILY_UPDATE_HOUR,
                minute=settings.DAILY_UPDATE_MINUTE,
                timezone=settings.TIMEZONE
            ),
            id='daily_news_update',
            replace_existing=True
        )
        
        # Check user email schedules every hour
        # This allows each user to have their own schedule
        scheduler.add_job(
            send_scheduled_emails,
            IntervalTrigger(
                hours=1,  # Check every hour
                timezone=settings.TIMEZONE
            ),
            id='check_user_email_schedules',
            replace_existing=True
        )
        
        scheduler.start()
        logger.info(
            f"Scheduler started (optimized) - News update at {settings.DAILY_UPDATE_HOUR}:{settings.DAILY_UPDATE_MINUTE:02d}, "
            f"Email check every hour ({settings.TIMEZONE})"
        )
        
    except Exception as e:
        logger.error(f"Failed to start scheduler: {str(e)}")


def stop_scheduler():
    """Stop the scheduler"""
    if scheduler.running:
        scheduler.shutdown()
        logger.info("Scheduler stopped")
